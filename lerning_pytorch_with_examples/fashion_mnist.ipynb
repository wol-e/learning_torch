{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49ae0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f04c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml(name=\"Fashion-MNIST\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c17cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     8.0     2.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    23.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    59.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         13.0  ...     214.0     241.0      55.0       0.0       0.0   \n",
       "1          0.0  ...       2.0       1.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...     145.0     120.0      98.0       0.0       0.0   \n",
       "4         11.0  ...     130.0      89.0      40.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...     135.0     100.0      67.0       0.0       0.0   \n",
       "69998    207.0  ...      92.0       0.0       0.0       0.0       0.0   \n",
       "69999    147.0  ...     153.0     134.0       4.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[\"data\"]\n",
    "X[\"Target\"] = data[\"target\"]\n",
    "X = X.sample(frac=1).reset_index(drop=True)\n",
    "y = X[\"Target\"].copy()\n",
    "del X[\"Target\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd53d736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_image_by_index(i):\n",
    "    plt.imshow(X.iloc[i].values.reshape(28,28))\n",
    "    plt.title(f\"Target: {y.iloc[i]}\")\n",
    "\n",
    "\n",
    "plot_image_by_index(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822270c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplain random forest Accuracy: 0.8802597402597403\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forrest Classifier\n",
    "\"\"\"\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#model_rf = RandomForestClassifier()\n",
    "\n",
    "#model_rf.fit(X=X_train, y=y_train)\n",
    "\n",
    "#print(f\"\"\"\n",
    "#Acc Train: {accuracy_score(\n",
    "#    y_true=y_train,\n",
    "#    y_pred=model_rf.predict(X_train),\n",
    "#)}\n",
    "\n",
    "#Acc Test: {accuracy_score(\n",
    "#    y_true=y_test,\n",
    "#    y_pred=model_rf.predict(X_test),\n",
    "#)}\n",
    "#\"\"\")\n",
    "\n",
    "\"\"\"\n",
    "plain random forest Accuracy: 0.8802597402597403\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0029ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLet's beat it by learning torch\\n\\nBased on https://pytorch.org/tutorials/beginner/nn_tutorial.html\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's beat it by learning torch\n",
    "\n",
    "Based on https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cdeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_torch, X_test_torch, y_train_torch, y_test_torch = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c3791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966226c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pandas to torch\"\"\"\n",
    "\n",
    "X_train_torch, y_train_torch, X_test_torch, y_test_torch = map(\n",
    "    torch.tensor, (\n",
    "        X_train_torch.values,\n",
    "        y_train_torch.to_numpy().astype(\"float\"),\n",
    "        X_test_torch.values,\n",
    "        y_test_torch.to_numpy().astype(\"float\")\n",
    "    )\n",
    ")\n",
    "\n",
    "X_train_torch, y_train_torch, X_test_torch, y_test_torch = \\\n",
    "    X_train_torch.double(), y_train_torch.long(), X_test_torch.double(), y_test_torch.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d455125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnn with torch tensors form scratch\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn with torch tensors form scratch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cbe6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(183.5433, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "1 tensor(105.3867, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "2 tensor(76.4675, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "3 tensor(111.7761, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "4 tensor(93.9172, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "5 tensor(89.0289, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "6 tensor(118.8034, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "7 tensor(84.5565, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "8 tensor(93.8247, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "9 tensor(52.5705, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "10 tensor(64.5386, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "100 tensor(9.3052, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "200 tensor(12.6193, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "300 tensor(24.9707, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "400 tensor(19.7237, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "500 tensor(11.3018, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "600 tensor(16.4027, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "700 tensor(19.9776, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "0 tensor(26.6481, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "1 tensor(52.6224, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "2 tensor(21.4433, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "3 tensor(17.6677, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "4 tensor(15.1318, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "5 tensor(23.5031, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "6 tensor(14.6758, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "7 tensor(18.2023, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "8 tensor(7.5963, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "9 tensor(10.1106, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "10 tensor(6.7526, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "100 tensor(1.7287, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "200 tensor(9.9728, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "300 tensor(8.9358, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "400 tensor(11.3383, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "500 tensor(10.0872, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "600 tensor(26.7304, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "700 tensor(15.2420, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(1.1369, dtype=torch.float64, grad_fn=<NegBackward0>) tensor(0.9250) tensor(0.7539)\n"
     ]
    }
   ],
   "source": [
    "# resetting weights and biases\n",
    "import math\n",
    "\n",
    "weights = (torch.randn(784, 10) / math.sqrt(784)).double()  # \"Xavier initialisation\"\n",
    "weights.requires_grad_()  # trailing _ in pytorch means \"inplace\"\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "def log_softmax(x):\n",
    "    \"\"\"\n",
    "    activation function\n",
    "    \"\"\"\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    \"\"\"\n",
    "    linear model layer with log softmax activation\n",
    "    param xb: training batch\n",
    "    \"\"\"\n",
    "    return log_softmax(xb @ weights + bias)  # @ is matrix multiplication\n",
    "\n",
    "def nll(preds, target):\n",
    "    \"\"\"\n",
    "    negative log likelihood\n",
    "    \"\"\"\n",
    "    return -preds[range(target.shape[0]), target].mean()  #TODO: where is the log?\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "\n",
    "loss_func = nll\n",
    "\n",
    "lr = 0.0001  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "n, c = X_train_torch.shape#\n",
    "bs = 60\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = X_train_torch[start_i:end_i]\n",
    "        yb = y_train_torch[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        if i % 100 == 0 or i <= 10:\n",
    "            print(i, loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "            \n",
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb), accuracy(model(X_test_torch), y_test_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Same now with nn module\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b61bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(197.0609, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "700 tensor(187.9925, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "0 tensor(197.0433, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "700 tensor(187.9754, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(182.3930, dtype=torch.float64, grad_fn=<NllLossBackward0>) tensor(0.1474)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ce_loss_func = F.cross_entropy\n",
    "\n",
    "class FMnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr = .1  # learning rate\n",
    "        self.epochs = 10\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784)).double()\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias\n",
    "    \n",
    "\n",
    "    def fit(self):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range((n - 1) // bs + 1):\n",
    "                start_i = i * bs\n",
    "                end_i = start_i + bs\n",
    "                xb = X_train_torch[start_i:end_i]\n",
    "                yb = y_train_torch[start_i:end_i]\n",
    "                pred = model(xb)\n",
    "                #loss = loss_func(pred, yb)\n",
    "                loss = ce_loss_func(pred, yb)\n",
    "                if i % 700 == 0 :\n",
    "                    print(i, loss)\n",
    "\n",
    "                loss.backward()\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        p -= p.grad * lr\n",
    "                    model.zero_grad()\n",
    "        print(ce_loss_func(model(xb), yb), accuracy(model(X_test_torch), y_test_torch))\n",
    "\n",
    "model = FMnist_Logistic()\n",
    "model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
